{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPp1JS/zp9Mo8y/iats2azA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shusank8/Transformers/blob/main/Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlMNuiFh-P7k",
        "outputId": "bc045d95-dcf5-463e-e5e2-e838623f3606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformers.... Excited\n"
          ]
        }
      ],
      "source": [
        "print(\"Transformers.... Excited\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "s9kj-4Uh-U5j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config = {\n",
        "#     \"batch_size\":8,\n",
        "#     \"num_epochs\":20,\n",
        "#     \"lr\":10**-4,\n",
        "#     \"block_size\":512,\n",
        "#     \"embdim\":512,\n",
        "# }"
      ],
      "metadata": {
        "id": "eV07JB1yt8Js"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputEmbeddings(nn.Module):\n",
        "\n",
        "  def __init__(self, vocab_size, embdim):\n",
        "    super().__init__()\n",
        "    self.embeddings = nn.Embedding(vocab_size, embdim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "1XEfUQea_NFA"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbeddings(nn.Module):\n",
        "\n",
        "  def __init__(self, block_size, embdim, dropout):\n",
        "    super().__init__()\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    pe = torch.zeros(block_size, embdim)\n",
        "\n",
        "    position = torch.arange(0, block_size, dtype = torch.float).unsqueeze(1)\n",
        "\n",
        "    div_term = torch.exp(torch.arange(0, embdim, 2).float() * (-math.log(10000.0)/embdim))\n",
        "\n",
        "    pe[:, 0::2] = torch.sin(position*div_term)\n",
        "    pe[:, 1::2] = torch.cos(position*div_term)\n",
        "    pe = pe.unsqueeze(0)\n",
        "    self.register_buffer('pe', pe)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x+ self.pe[:, :x.shape[1],:]\n",
        "\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "cBbwQQ9t_oO_"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNormalization(nn.Module):\n",
        "\n",
        "  def __init__(self, embdim):\n",
        "    super().__init__()\n",
        "    self.eps = 10**-6\n",
        "    self.alpha = nn.Parameter(torch.ones(embdim))\n",
        "    self.bias = nn.Parameter(torch.zeros(embdim))\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    xmean = x.mean(dim=-1, keepdim=True)\n",
        "    xvar = x.var(dim=-1, keepdim=True)\n",
        "    x = self.alpha*((x-xmean)/(xvar+self.eps)**(1/2))+self.bias\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "47y2lRPNJWO5"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "\n",
        "  def __init__(self, embdim, dropout):\n",
        "    super().__init__()\n",
        "    self.m = nn.Sequential(\n",
        "        nn.Linear(embdim, 3*embdim),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3*embdim, embdim),\n",
        "        nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    x = self.m(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "22KaQUo4d0IU"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttentionBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, embdim, no_of_heads, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embdim = embdim\n",
        "    self.q = nn.Linear(embdim, embdim)\n",
        "    self.k = nn.Linear(embdim, embdim)\n",
        "    self.v = nn.Linear(embdim, embdim)\n",
        "    self.proj = nn.Linear(embdim, embdim)\n",
        "    self.no_of_heads = no_of_heads\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  @staticmethod\n",
        "  def attention(query, key, value, mask, dropout):\n",
        "    head_dim = query.shape[-1]\n",
        "    attention_scores = (query@key.transpose(-2,-1))/math.sqrt(head_dim)\n",
        "    if mask is not None:\n",
        "      attention_scores.masked_fill(mask==0, float(\"-inf\"))\n",
        "\n",
        "    attention_scores = attention_scores.softmax(dim=-1)\n",
        "    if dropout is not None:\n",
        "      attention_scores = dropout(attention_scores)\n",
        "    return (attention_scores@value), attention_scores\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, query, key, val, mask):\n",
        "\n",
        "    # for self attn query==key==val but cross attn\n",
        "    q = self.q(query)\n",
        "    k = self.k(key)\n",
        "    v = self.v(val)\n",
        "    hdim = q.shape[-1]//self.no_of_heads\n",
        "    # shape of q=> (B, T, C) BUT WE WANT TO BREAK C INTO DIFF HEADS\n",
        "    # (B,T,NO_OF_HEADS, HEADIM) WHERE NO_OF_HEADS * HEADIM = C\n",
        "    q = q.view(q.shape[0], q.shape[1], self.no_of_heads, hdim).transpose(1,2)\n",
        "    k = k.view(k.shape[0], k.shape[1], self.no_of_heads, hdim).transpose(1,2)\n",
        "    v = v.view(v.shape[0], v.shape[1], self.no_of_heads, hdim).transpose(1,2)\n",
        "\n",
        "    x, attn_scores = MultiHeadAttentionBlock.attention(q, k, v, mask, self.dropout)\n",
        "    x = x.transpose(1,2).contiguous().view(x.shape[0], -1, self.embdim)\n",
        "    x = self.proj(x)\n",
        "\n",
        "    return self.proj(x)\n"
      ],
      "metadata": {
        "id": "2JJniu-nhLue"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualConnection(nn.Module):\n",
        "  def __init__(self, dropout, embdim):\n",
        "    super().__init__()\n",
        "    self.dropout  = nn.Dropout(dropout)\n",
        "    self.norm = LayerNormalization(embdim)\n",
        "\n",
        "  def forward(self, x, sublayer):\n",
        "\n",
        "    x = x+ self.dropout(sublayer(self.norm(x)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "9SBXl1nWrDN1"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderBlock(nn.Module):\n",
        "\n",
        "  def __init__(self, embdim, s_attn, ffwd, dropout):\n",
        "    super().__init__()\n",
        "    self.selfattn = s_attn\n",
        "    self.ffwd = ffwd\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(dropout,embdim) for _ in range(2)])\n",
        "\n",
        "  def forward(self, x, src_mask):\n",
        "    x = self.residual_connections[0](x, lambda x: self.selfattn(x,x,x,src_mask))\n",
        "    x = self.residual_connections[1](x, self.ffwd)\n",
        "    return x"
      ],
      "metadata": {
        "id": "RoemyhuTri-H"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "  def __init__(self, layers, embdim):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization(embdim)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    return self.norm(x)"
      ],
      "metadata": {
        "id": "CUJf-6U5VruM"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embdim, selfattn, crossattn, ffwd, dropout):\n",
        "    super().__init__()\n",
        "    self.selfattn = selfattn\n",
        "    self.crossattn = crossattn\n",
        "    self.ffwd = ffwd\n",
        "    self.residual_connections = nn.ModuleList([ResidualConnection(dropout,embdim) for _ in range(3)])\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    x = self.residual_connections[0](x, lambda x: self.selfattn(x,x,x, tgt_mask))\n",
        "    x = self.residual_connections[1](x, lambda x: self.crossattn(x, encoder_output, encoder_output, src_mask))\n",
        "    x = self.residual_connections[2](x, self.ffwd)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k7eGnV3iXdX6"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "\n",
        "  def __init__(self, layers, embdim):\n",
        "    super().__init__()\n",
        "    self.layers = layers\n",
        "    self.norm = LayerNormalization(embdim)\n",
        "\n",
        "  def forward(self, x, encoder_output, src_mask, tgt_mask):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "    return self.norm(x)"
      ],
      "metadata": {
        "id": "8cxmS95SYn-O"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, embdim, vocab_size):\n",
        "    super().__init__()\n",
        "    self.proj = nn.Linear(embdim, vocab_size)\n",
        "  def forward(self, x):\n",
        "    return torch.log_softmax(self.proj(x), dim=-1)"
      ],
      "metadata": {
        "id": "MCt-sgmdZBzd"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, src_embed, tgt_embd, src_pos, tgt_pos, projection_layer):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embd = src_embed\n",
        "    self.tgt_embd = tgt_embd\n",
        "    self.src_pos = src_pos\n",
        "    self.tgt_pos = tgt_pos\n",
        "    self.proj_layer = projection_layer\n",
        "\n",
        "  def encode(self, src, src_mask):\n",
        "    src = self.src_embd(src)\n",
        "    src = self.src_pos(src)\n",
        "    return self.encoder(src, src_mask)\n",
        "\n",
        "  def decode(self, encoder_output, src_mask, tgt, tgt_mask):\n",
        "    tgt = self.tgt_embd(tgt)\n",
        "    tgt = self.tgt_pos(tgt)\n",
        "    return self.decoder(tgt, encoder_output, src_mask, tgt_mask)\n",
        "\n",
        "  def projection(self, x):\n",
        "    return self.proj_layer(x)\n"
      ],
      "metadata": {
        "id": "n5wYngTxZYs4"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_transformer(src_vocab_size,tgt_vocab_size, src_seq_len, tgt_seq_len, embdim, n_of_layers, no_of_heads, dropout):\n",
        "  src_embd = InputEmbeddings(src_vocab_size, embdim)\n",
        "  tgt_embd = InputEmbeddings(tgt_vocab_size, embdim)\n",
        "\n",
        "  src_pos = PositionalEmbeddings(src_seq_len, embdim, dropout)\n",
        "  tgt_pos = PositionalEmbeddings(tgt_seq_len, embdim, dropout)\n",
        "\n",
        "  encoder_blocks = []\n",
        "  for _ in range(n_of_layers):\n",
        "    encoder_sa = MultiHeadAttentionBlock(embdim, no_of_heads, dropout)\n",
        "    encoder_ffd = FeedForward(embdim, dropout)\n",
        "    encoder_block = EncoderBlock(embdim,encoder_sa, encoder_ffd, dropout)\n",
        "    encoder_blocks.append(encoder_block)\n",
        "  decoder_blocks = []\n",
        "  for _ in range(n_of_layers):\n",
        "    decoder_sa1 = MultiHeadAttentionBlock(embdim, no_of_heads, dropout)\n",
        "    decoder_ca = MultiHeadAttentionBlock(embdim, no_of_heads, dropout)\n",
        "    decoder_ffd = FeedForward(embdim, dropout)\n",
        "    decoder_block = DecoderBlock(embdim, decoder_sa1, decoder_ca, decoder_ffd, dropout)\n",
        "    decoder_blocks.append(decoder_block)\n",
        "\n",
        "  encoder = Encoder(nn.ModuleList(encoder_blocks), embdim)\n",
        "  decoder = Decoder(nn.ModuleList(decoder_blocks), embdim)\n",
        "\n",
        "  projection_layer = ProjectionLayer(embdim, tgt_vocab_size)\n",
        "\n",
        "  transformer = Transformer(encoder, decoder, src_embd, tgt_embd, src_pos, tgt_pos, projection_layer)\n",
        "\n",
        "  # initialize the parameters\n",
        "  for p in transformer.parameters():\n",
        "    if p.dim()>=2:\n",
        "      nn.init.xavier_uniform_(p)\n",
        "  return transformer\n",
        "\n"
      ],
      "metadata": {
        "id": "EkePWWGPas1C"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jsVDKc44oZm",
        "outputId": "9f6473fa-b04f-4425-da87-dab3bde43dbc"
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ni8vNmaj8YCv"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "ds = load_dataset(\"iamTangsang/Nepali-to-English-Translation-Dataset\")\n",
        "\n",
        "# Convert each split (train, test, validation) to Pandas DataFrame\n",
        "df_train = ds['train'].to_pandas() if 'train' in ds else None\n",
        "df_test = ds['test'].to_pandas() if 'test' in ds else None\n",
        "df_valid = ds['validation'].to_pandas() if 'validation' in ds else None\n"
      ],
      "metadata": {
        "id": "Cz6Sv66ODX5O"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, df_valid], ignore_index=True)"
      ],
      "metadata": {
        "id": "n6g3uc828Q23"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns = ['tgt', 'src']\n",
        "df_test.columns = ['tgt', 'src']"
      ],
      "metadata": {
        "id": "qBL8O9D36kCq"
      },
      "execution_count": 403,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['tgt_len'] = df_train['tgt'].apply(lambda x : len(x.split(\" \")))"
      ],
      "metadata": {
        "id": "wpU0bo0jFMxH"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['src_len'] = df_train['src'].apply(lambda x:len(x.split(\" \")))"
      ],
      "metadata": {
        "id": "pjp7qophAusz"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_train = df_train[df_train['tgt_len']<100]"
      ],
      "metadata": {
        "id": "O3mSakQBA5Jn"
      },
      "execution_count": 406,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train['src_len']\n",
        "df_train = df_train[df_train['src_len']<100]"
      ],
      "metadata": {
        "id": "ZIi_fV0FBigD"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['tgt_len'] = df_test['tgt'].apply(lambda x : len(x.split(\" \")))\n",
        "df_test['src_len'] = df_test['src'].apply(lambda x:len(x.split(\" \")))\n",
        "df_test = df_test[df_test['tgt_len']<100]\n",
        "df_test = df_test[df_test['src_len']<100]"
      ],
      "metadata": {
        "id": "SA8e3GrbBvuC"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SOURCE TEXT => ENGLISH\n",
        "# TARGET TEXT => NEPALI"
      ],
      "metadata": {
        "id": "3Q4s2U3dGIbu"
      },
      "execution_count": 409,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.models import BPE, WordLevel\n",
        "import os\n",
        "def create_or_load_tokenizer(df):\n",
        "  if os.path.exists(\"SourceTokenizer.json\"):\n",
        "    srctok = Tokenizer.from_file(\"SourceTokenizer.json\")\n",
        "    tgttok = Tokenizer.from_file(\"TargetTokenizer.json\")\n",
        "    return srctok, tgttok\n",
        "  else:\n",
        "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "    trainer = WordLevelTrainer(special_tokens=[\"[UNK]\",  \"[PAD]\", \"[SOS]\", \"[EOS]\"], vocab_size = 50000, min_frequency=8)\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    tokenizer.train_from_iterator(df_train['src'], trainer=trainer)\n",
        "    tokenizer.save(\"SourceTokenizer.json\")\n",
        "    tokenizer.train_from_iterator(df_train['tgt'], trainer=trainer)\n",
        "    tokenizer.save(\"TargetTokenizer.json\")\n",
        "    srctokenizer = Tokenizer.from_file(\"SourceTokenizer.json\")\n",
        "    targettokenizer = Tokenizer.from_file(\"TargetTokenizer.json\")\n",
        "    return srctokenizer, targettokenizer"
      ],
      "metadata": {
        "id": "BroBNjtW8bmO"
      },
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_tok, tgt_tok = create_or_load_tokenizer(df_train)"
      ],
      "metadata": {
        "id": "AlplQDDc9oBC"
      },
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_tok.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT5FqbOwAb-h",
        "outputId": "cbd0adcd-26cd-4b66-98a0-9e5bc5eb098e"
      },
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20648"
            ]
          },
          "metadata": {},
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tgt_tok.get_vocab_size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk9hOsyK9vzU",
        "outputId": "7c032ad1-f890-42fa-f9d4-7fd92c5f1a77"
      },
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35974"
            ]
          },
          "metadata": {},
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class BiDataSet(Dataset):\n",
        "\n",
        "  def __init__(self, df, src_tok, tgt_tok,  block_size):\n",
        "    self.df = df\n",
        "    self.src_tok = src_tok\n",
        "    self.tgt_tok = tgt_tok\n",
        "    self.block_size = block_size\n",
        "\n",
        "    self.eos_tok = torch.tensor([src_tok.token_to_id(\"[EOS]\")], dtype = torch.int64)\n",
        "    self.sos_tok = torch.tensor([src_tok.token_to_id(\"[SOS]\")], dtype = torch.int64)\n",
        "    self.pad_tok = torch.tensor([src_tok.token_to_id(\"[PAD]\")], dtype = torch.int64)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    df = self.df.iloc[index]\n",
        "    src_text = df['src']\n",
        "    tgt_text = df['tgt']\n",
        "\n",
        "    enc_inp_tokens = self.src_tok.encode(src_text).ids\n",
        "    dec_inp_tokens = self.tgt_tok.encode(tgt_text).ids\n",
        "\n",
        "    enc_num_padding_tok = self.block_size - len(enc_inp_tokens)-2\n",
        "    dec_num_padding_tok = self.block_size - len(dec_inp_tokens)-1\n",
        "\n",
        "    if enc_num_padding_tok < 0 or dec_num_padding_tok<0:\n",
        "      raise ValueError(\"Sentence is too long\")\n",
        "\n",
        "    encoder_input = torch.cat([\n",
        "        self.sos_tok,\n",
        "        torch.tensor(enc_inp_tokens, dtype = torch.int64),\n",
        "        self.eos_tok,\n",
        "        torch.tensor([self.pad_tok]*enc_num_padding_tok, dtype=torch.int64)\n",
        "    ])\n",
        "\n",
        "    decoder_input = torch.cat([\n",
        "        self.sos_tok,\n",
        "        torch.tensor(dec_inp_tokens, dtype = torch.int64),\n",
        "        torch.tensor([self.pad_tok]*dec_num_padding_tok, dtype=torch.int64)\n",
        "    ])\n",
        "\n",
        "    label = torch.cat(\n",
        "        [\n",
        "            torch.tensor(dec_inp_tokens, dtype = torch.int64),\n",
        "            self.eos_tok,\n",
        "            torch.tensor([self.pad_tok]*dec_num_padding_tok, dtype=torch.int64)\n",
        "\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    assert encoder_input.size(0)==self.block_size\n",
        "    assert decoder_input.size(0)==self.block_size\n",
        "    assert label.size(0)==self.block_size\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"encoder_input\":encoder_input,\n",
        "        \"decoder_input\":decoder_input,\n",
        "        \"encoder_mask\":(encoder_input!=self.pad_tok).unsqueeze(0).unsqueeze(0).int(),\n",
        "        \"decoder_mask\":(decoder_input!=self.pad_tok).unsqueeze(0).unsqueeze(0).int() & causal_mask(decoder_input.size(0)),\n",
        "        \"label\":label,\n",
        "        'src_text':src_text,\n",
        "        'tgt_text':tgt_text\n",
        "    }\n",
        "\n",
        "def causal_mask(size):\n",
        "  mask = torch.tril(torch.ones(1, size, size)).type(torch.int)\n",
        "  return mask==1\n"
      ],
      "metadata": {
        "id": "6gfr0BM-DxLA"
      },
      "execution_count": 414,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train), len(df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFh0aUkkgD1l",
        "outputId": "9db6c35e-02d0-438e-8681-7d75045dbaf8"
      },
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(713424, 10864)"
            ]
          },
          "metadata": {},
          "execution_count": 415
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# block_size = config['block_size']\n",
        "block_size = 130\n",
        "train_ds = BiDataSet(df_train,src_tok, tgt_tok, block_size )\n",
        "val_ds = BiDataSet(df_test,src_tok, tgt_tok, block_size )"
      ],
      "metadata": {
        "id": "EQyhoKnNhB1F"
      },
      "execution_count": 416,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len_src = 0\n",
        "# max_len_tgt = 0"
      ],
      "metadata": {
        "id": "fnqvsnBzhStJ"
      },
      "execution_count": 417,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = 0\n",
        "# ts = 0\n",
        "# for item in df_train['src']:\n",
        "#   src_ids = src_tok.encode(item).ids\n",
        "#   # tgt_ids = tgt_tok.encode(item['tgt']).ids\n",
        "#   max_len_src = max(max_len_src, len(src_ids))\n",
        "#   ts+=len(src_ids)\n",
        "#   # max_len_tgt = max(max_len_tgt, tgt_ids)"
      ],
      "metadata": {
        "id": "WixGLP7ihXqe"
      },
      "execution_count": 418,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x = 0\n",
        "# s = 0\n",
        "# for item in df_train['tgt']:\n",
        "#   # src_ids = src_tok.encode(item).ids\n",
        "#   tgt_ids = tgt_tok.encode(item).ids\n",
        "#   # max_len_src = max(max_len_src, len(src_ids))\n",
        "#   max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
        "#   s+=len(tgt_ids)"
      ],
      "metadata": {
        "id": "KFFdh2-4huAU"
      },
      "execution_count": 419,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_len_src, max_len_tgt"
      ],
      "metadata": {
        "id": "onZr4Ar2iKeh"
      },
      "execution_count": 420,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 64\n",
        "train_dataloader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=20)\n",
        "val_dataloader = DataLoader(val_ds, batch_size, shuffle=True,num_workers=20)\n"
      ],
      "metadata": {
        "id": "dmko40xOiw2z"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for x in iter(train_dataloader):\n",
        "#   inp = x\n",
        "#   break"
      ],
      "metadata": {
        "id": "MDT2whQapSxx"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_transformer(src_tok.get_vocab_size(), tgt_tok.get_vocab_size(), 130,130, 128, 1, 4, 0.2)\n",
        "model = model.to(\"cuda\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 10**-4, eps = 1e-9)"
      ],
      "metadata": {
        "id": "JiqDq5DTsFHz"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn  = nn.CrossEntropyLoss(ignore_index=src_tok.token_to_id('[PAD]'), label_smoothing=0.1).to(\"cuda\")"
      ],
      "metadata": {
        "id": "UBSxKIGmDGa8"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "  for i, batch in enumerate(train_dataloader):\n",
        "\n",
        "    encoder_input = batch['encoder_input'].to(\"cuda\")\n",
        "    decoder_input = batch['decoder_input'].to(\"cuda\")\n",
        "    encoder_mask = batch['encoder_mask'].to(\"cuda\")\n",
        "    decoder_mask = batch['decoder_mask'].to(\"cuda\")\n",
        "    label = batch['label'].to(\"cuda\")\n",
        "    src_text = batch['src_text']\n",
        "    tgt_text = batch['tgt_text']\n",
        "\n",
        "    encoder_output = model.encode(encoder_input, encoder_mask)\n",
        "    decoder_output = model.decode(encoder_output, encoder_mask, decoder_input, decoder_mask)\n",
        "    proj = model.projection(decoder_output)\n",
        "\n",
        "    loss = loss_fn(proj.view(-1, tgt_tok.get_vocab_size()), label.view(-1))\n",
        "\n",
        "    if i%500==0:\n",
        "      print(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCr-uAIQJ0Ag",
        "outputId": "b46fcaf7-173c-42d7-d36d-a74ff86ac298"
      },
      "execution_count": 461,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.463043689727783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwD8M5JBJ89R",
        "outputId": "bd43fea5-3214-4d82-cd08-cd23611e3e35"
      },
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 130])"
            ]
          },
          "metadata": {},
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woGmsq4sKXbK",
        "outputId": "3349fb1c-7488-4dc3-f4e5-56ae34f33ab9"
      },
      "execution_count": 426,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 130])"
            ]
          },
          "metadata": {},
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4BEk3X5K4_V",
        "outputId": "2e388bf5-98f3-4e7b-b340-4b9544352caa"
      },
      "execution_count": 427,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 1, 130])"
            ]
          },
          "metadata": {},
          "execution_count": 427
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d60pjQNK6vY",
        "outputId": "7f2fad6d-659a-4b4a-b56f-6f459f1cac52"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faT-omUBK9TC",
        "outputId": "e14c3337-68e0-49ec-8b8b-458fb29625db"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(proj.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9D1JaMv0K--u",
        "outputId": "5f19955e-ae79-4ae0-886f-a66b732fd9b6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 164, 35974])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(encoder_output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1l3x5vZMA2c",
        "outputId": "4fd15e72-cb0d-4dd0-9018-3ae7bf6a0190"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 164, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decoder_output.shape)"
      ],
      "metadata": {
        "id": "83FSBedgNvFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTXeni7iNxVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}